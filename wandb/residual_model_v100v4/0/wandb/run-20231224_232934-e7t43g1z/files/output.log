#frames list: [119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119]
#frames list: [119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119]
Train dataset size: 56658
prior model #params: 443560
residual model #params: 446260
Loading saved prior ckpt from /home/tianyang/Robocake/prior/dump_ngrip_fixed_desktop/3/prior_net_epoch_99_iter_1325/prior_model.pth
phase train
epoch 0
Epoch 0/5000:   0%|                  | 0/4722 [00:00<?, ?it/s]/home/tianyang/anaconda3/envs/test/lib/python3.7/site-packages/torch/distributed/distributed_c10d.py:153: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
residual train epoch[0/5000] iter[0/4722] LR: 0.000100, loss: 0.037573 (0.027854), loss_raw: 0.07606395 (0.07652913)
std_cluster None


Epoch 0/5000:   0%|       | 11/4722 [00:20<2:22:47,  1.82s/it]
Epoch 0/5000:   0%|                   | 0/570 [00:00<?, ?it/s]
residual train epoch[0/5000] Loss: 0.029366, Best valid: inf
phase valid
epoch 0
residual valid epoch[0/5000] iter[0/570] LR: 0.000100, loss: 0.035887 (0.026917), loss_raw: 0.07920529 (0.07920032)




Epoch 0/5000:   2%|▏         | 11/570 [00:13<05:01,  1.85it/s]
residual valid epoch[0/5000] Loss: 0.029057, Best valid: inf
phase train
Epoch 0/5000:   2%|▏         | 11/570 [00:16<13:34,  1.46s/it]
Epoch 1/5000:   0%|                  | 0/4722 [00:00<?, ?it/s]
residual train epoch[1/5000] iter[0/4722] LR: 0.000100, loss: 0.038928 (0.029166), loss_raw: 0.07456599 (0.07569346)




Epoch 1/5000:   0%|       | 11/4722 [00:17<2:02:39,  1.56s/it]
Epoch 1/5000:   0%|                   | 0/570 [00:00<?, ?it/s]
residual train epoch[1/5000] Loss: 0.029379, Best valid: 0.029057
phase valid
epoch 1
residual valid epoch[1/5000] iter[0/570] LR: 0.000100, loss: 0.037673 (0.028180), loss_raw: 0.07733723 (0.07695040)



Epoch 1/5000:   2%|▏         | 11/570 [00:14<05:09,  1.81it/s]
residual valid epoch[1/5000] Loss: 0.028594, Best valid: 0.029057
phase train
Epoch 1/5000:   2%|▏         | 11/570 [00:16<14:03,  1.51s/it]
Epoch 2/5000:   0%|                  | 0/4722 [00:00<?, ?it/s]
residual train epoch[2/5000] iter[0/4722] LR: 0.000100, loss: 0.038643 (0.028776), loss_raw: 0.07577273 (0.07593519)



Epoch 2/5000:   0%|       | 11/4722 [00:17<2:03:12,  1.57s/it]
Epoch 2/5000:   0%|                   | 0/570 [00:00<?, ?it/s]
residual train epoch[2/5000] Loss: 0.028291, Best valid: 0.028594
phase valid
epoch 2
residual valid epoch[2/5000] iter[0/570] LR: 0.000100, loss: 0.037713 (0.028239), loss_raw: 0.07589968 (0.07535275)



